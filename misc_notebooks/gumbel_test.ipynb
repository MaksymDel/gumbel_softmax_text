{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Gumbel softmax trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_batch = torch.rand(2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8903, 0.0851, 0.0877, 0.9698],\n",
       "        [0.8826, 0.7688, 0.6005, 0.0711]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1.]]) \n",
      "\n",
      "tensor([[0., 0., 0., 1.],\n",
      "        [0., 0., 1., 0.]]) \n",
      "\n",
      "tensor([[0., 0., 0., 1.],\n",
      "        [0., 0., 1., 0.]]) \n",
      "\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0.]]) \n",
      "\n",
      "tensor([[0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0.]]) \n",
      "\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0.]]) \n",
      "\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0.]]) \n",
      "\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0.]]) \n",
      "\n",
      "tensor([[0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.]]) \n",
      "\n",
      "tensor([[0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(F.gumbel_softmax(logits_batch, tau=1e-1, hard=True, eps=1e-10), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_batch[0,0] = 2\n",
    "logits_batch[1,1] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.0000, 0.0851, 0.0877, 0.9698],\n",
       "        [0.8826, 2.0000, 0.6005, 0.0711]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0.]]) \n",
      "\n",
      "tensor([[0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0.]]) \n",
      "\n",
      "tensor([[0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0.]]) \n",
      "\n",
      "tensor([[0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1.]]) \n",
      "\n",
      "tensor([[0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0.]]) \n",
      "\n",
      "tensor([[0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0.]]) \n",
      "\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.]]) \n",
      "\n",
      "tensor([[0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.]]) \n",
      "\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0.]]) \n",
      "\n",
      "tensor([[0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(F.gumbel_softmax(logits_batch, tau=10, hard=True, eps=1e-10), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1764, 0.3665, 0.1610, 0.2961],\n",
      "        [0.1431, 0.2883, 0.2027, 0.3659]]) \n",
      "\n",
      "tensor([[0.2561, 0.1983, 0.1751, 0.3705],\n",
      "        [0.1437, 0.2956, 0.3569, 0.2038]]) \n",
      "\n",
      "tensor([[0.2536, 0.2148, 0.2223, 0.3093],\n",
      "        [0.2021, 0.4020, 0.2335, 0.1623]]) \n",
      "\n",
      "tensor([[0.3385, 0.2450, 0.1511, 0.2655],\n",
      "        [0.3400, 0.2450, 0.1885, 0.2265]]) \n",
      "\n",
      "tensor([[0.3214, 0.2519, 0.1957, 0.2310],\n",
      "        [0.2897, 0.3067, 0.2036, 0.2000]]) \n",
      "\n",
      "tensor([[0.2807, 0.2325, 0.2630, 0.2238],\n",
      "        [0.2330, 0.4279, 0.1962, 0.1428]]) \n",
      "\n",
      "tensor([[0.4095, 0.1412, 0.2328, 0.2166],\n",
      "        [0.1730, 0.2342, 0.3916, 0.2012]]) \n",
      "\n",
      "tensor([[0.3874, 0.1951, 0.2081, 0.2094],\n",
      "        [0.2767, 0.2416, 0.2799, 0.2018]]) \n",
      "\n",
      "tensor([[0.2949, 0.2566, 0.2129, 0.2356],\n",
      "        [0.2818, 0.2871, 0.1796, 0.2515]]) \n",
      "\n",
      "tensor([[0.2576, 0.2101, 0.1794, 0.3529],\n",
      "        [0.3502, 0.2182, 0.2016, 0.2300]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(F.gumbel_softmax(logits_batch, tau=5, hard=False, eps=1e-10), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:konstrukt]",
   "language": "python",
   "name": "conda-env-konstrukt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
